# -*- coding: utf-8 -*-
"""orph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RiFLp3GkOQjeHgasW8rdl59s2C9x7n4i

    



# File sorting
"""
# from flask import Flask, render_template, request
# from keras.models import load_model

from __init__ import *

#####
from keras.saving import register_keras_serializable
from flask import Flask, render_template, send_from_directory
from flask_cors import CORS
from flask import session
import secrets


@register_keras_serializable()
def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):
    mse = (y_true - y_pred) ** 2
    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)
    return tf.reduce_mean(mse + positive_pressure)
#####


all_notes = pd.read_pickle('all_notes.pkl')
seq_length = 50
seq_length_classical = 100
vocab_size = 128


key_order = ['pitch', 'step', 'duration']
train_notes = np.stack([all_notes[key] for key in key_order], axis=1)
notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)
notes_ds.element_spec

#Flask
app= Flask(__name__)
CORS(app)

app.secret_key = secrets.token_hex(16)
"""# Generation

"""
model = load_model('model_weightbluesHUH.h5', custom_objects={'mse_with_positive_pressure': mse_with_positive_pressure}, compile=True, safe_mode=True)
print("model (blues) loaded successfully")

model_classical = load_model('classical2.h5', custom_objects={'mse_with_positive_pressure': mse_with_positive_pressure}, compile=True, safe_mode=True)
print("model (classical) loaded successfully")

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
      program=pretty_midi.instrument_name_to_program(
          instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(prev_start + note['step'])
    end = float(start + note['duration'])
    note = pretty_midi.Note(
        velocity=velocity,
        pitch=int(note['pitch']),
        start=start,
        end=end,
    )
    instrument.notes.append(note)
    prev_start = start

  pm.instruments.append(instrument)
  pm.write(out_file)
  return pm

import random
def blues_scale(pitch):
    """Adjusts generated pitch to fit the minor blues scale"""
    # Fixed pitches based on theory (1, 3b, 4, 5b, 5, 7b)
    # Hard code?
    blues_scale_pitches = [52, 55, 57, 58, 59, 62]

    # Check if the pitch is in the blues scale
    if pitch in blues_scale_pitches:
        return pitch
    else:
        # Find the nearest pitch in the blues scale
        diff = [abs(pitch - p) for p in blues_scale_pitches]
        nearest_pitch_index = diff.index(min(diff))
        # Randomise for another index
        random_index = random.choice([-1, 1])
        new_index = nearest_pitch_index + random_index

        # Constraint for boumnds
        if new_index < 0:
            new_index = 0
        elif new_index >= len(blues_scale_pitches):
            new_index = len(blues_scale_pitches) - 1

        return blues_scale_pitches[new_index]

def predict_next_note(notes: np.ndarray, model: tf.keras.Model, temperature: float = 1.0) -> tuple[int, float, float]:
    """Generates a note as a tuple of (pitch, step, duration), using a trained sequence model."""
    assert temperature > 0

    # Add batch dimension
    inputs = tf.expand_dims(notes, 0)

    predictions = model.predict(inputs)
    pitch_logits = predictions['pitch']
    step = predictions['step']
    duration = predictions['duration']

    pitch_logits /= temperature
    pitch = tf.random.categorical(pitch_logits, num_samples=1)
    pitch = tf.squeeze(pitch, axis=-1)
    duration = tf.squeeze(duration, axis=-1)
    step = tf.squeeze(step, axis=-1)

    # `step` and `duration` values should be non-negative
    step = tf.maximum(0, step)
    duration = tf.maximum(0, duration)
    #blues scale
    pitch = blues_scale(int(pitch))
    #keep within octave
    pitch = tf.clip_by_value(pitch, 52, 62)

    
    print(f"Generated Note: Pitch={pitch}, Step={step}, Duration={duration}")

    return int(pitch), float(step), float(duration)


@app.route('/')
def index():
  return render_template('index.html')


@app.route('/test')
def test():
  return render_template('test.html')


@app.route('/blues', methods=['GET', 'POST'])
def blues():
    #  List of pickable instruments
    instrument_programs = [
        (30, 'Distortion Guitar'),
        (33, 'Electric Bass'),
        (65, 'Alto Saxophone'),
        
    ]
    selected_program = session.get('selected_program', 30)
    
    if request.method == 'POST':
        # Update from client-side
        selected_program_value = request.form.get('selected_program')
        
        # Logic for sessions and consitency
        if selected_program_value:
            # Convert
            selected_program = int(selected_program_value)
            # Store 
            session['selected_program'] = selected_program
        
        session['selected_program'] = selected_program
        # The generation
        temperature = 1.5
        num_predictions = 16
        sample_notes = np.stack([all_notes[key] for key in key_order], axis=1)
        input_notes = (sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))
        generated_notes = []
        prev_start = 0
        for _ in range(num_predictions):
            pitch, step, duration = predict_next_note(input_notes, model, temperature)
            start = prev_start + step
            end = start + duration
            input_note = (pitch, step, duration)
            generated_notes.append((*input_note, start, end))
            input_notes = np.delete(input_notes, 0, axis=0)
            input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)
            prev_start = start

        generated_notes = pd.DataFrame(generated_notes, columns=(*key_order, 'start', 'end'))
        pitch_counts = generated_notes['pitch'].value_counts()
        print("Pitch Counts:")
        print(pitch_counts)

        out_file = 'static/blues.mid'
        print("MIDI file generated:", out_file)

        instrument = pretty_midi.Instrument(program=selected_program)
        instrument_name = pretty_midi.program_to_instrument_name(instrument.program)
        out_pm = notes_to_midi(generated_notes, out_file=out_file, instrument_name=instrument_name)

        #MIDI TO WAV
        audio_file = 'static/blues.wav'
        soundfont_path = os.path.join(os.path.dirname(__file__), 'static', 'Simone_Piervergili_s_Dist_Guitar.sf2')
        fs = FluidSynth(soundfont_path)
        fs.midi_to_audio(out_file, audio_file)

        print("MIDI file path:", out_file)

        return render_template('blues.html', midi_file=out_file, instrument_programs=instrument_programs)

    return render_template('blues.html', instrument_programs=instrument_programs, selected_program=selected_program)



def predict_next_note_classical(notes: np.ndarray, model: tf.keras.Model, temperature: float = 1.0) -> tuple[int, float, float]:
    """Generates a note as a tuple of (pitch, step, duration), using a trained sequence model."""
    assert temperature > 0

    # Add batch dimension
    inputs = tf.expand_dims(notes, 0)

    predictions = model_classical.predict(inputs)
    pitch_logits = predictions['pitch']
    step = predictions['step']
    duration = predictions['duration']

    pitch_logits /= temperature
    pitch = tf.random.categorical(pitch_logits, num_samples=1)
    pitch = tf.squeeze(pitch, axis=-1)
    duration = tf.squeeze(duration, axis=-1)
    step = tf.squeeze(step, axis=-1)

    # `step` and `duration` values should be non-negative
    step = tf.maximum(0, step)
    duration = tf.maximum(0, duration)
    
    
    print(f"Generated Note: Pitch={pitch}, Step={step}, Duration={duration}")

    return int(pitch), float(step), float(duration)





@app.route('/classical', methods=['GET', 'POST'])
def classical():
    #  List of pickable instruments
    instrument_programs = [
        (1, 'Bright Acoustic Piano'),
        (41, 'Viola'),
        (71, 'Clarinet'),
        
    ]
    selected_program = session.get('selected_program', 1)
    
    if request.method == 'POST':
        # Update from client-side
        selected_program_value = request.form.get('selected_program')
        
        # Logic for sessions and consitency
        if selected_program_value:
            # Convert
            selected_program = int(selected_program_value)
            # Store 
            session['selected_program'] = selected_program
        
        session['selected_program'] = selected_program
        # The generation
        temperature = 1.5
        num_predictions = 16
        sample_notes = np.stack([all_notes[key] for key in key_order], axis=1)
        input_notes = (sample_notes[:seq_length_classical] / np.array([vocab_size, 1, 1]))
        generated_notes = []
        prev_start = 0
        for _ in range(num_predictions):
            pitch, step, duration = predict_next_note_classical(input_notes, model, temperature)
            start = prev_start + step
            end = start + duration
            input_note = (pitch, step, duration)
            generated_notes.append((*input_note, start, end))
            input_notes = np.delete(input_notes, 0, axis=0)
            input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)
            prev_start = start

        generated_notes = pd.DataFrame(generated_notes, columns=(*key_order, 'start', 'end'))
        pitch_counts = generated_notes['pitch'].value_counts()
        print("Pitch Counts:")
        print(pitch_counts)

        out_file = 'static/classical.mid'
        print("MIDI file generated:", out_file)

        instrument = pretty_midi.Instrument(program=selected_program)
        instrument_name = pretty_midi.program_to_instrument_name(instrument.program)
        out_pm = notes_to_midi(generated_notes, out_file=out_file, instrument_name=instrument_name)
        print("MIDI file path:", out_file)

        #For MIDI to WAV
        audio_file = 'static/classical.wav'
        soundfont_path = os.path.join(os.path.dirname(__file__), 'static', 'Yamaha_C3_Grand_Piano.sf2')
        fs = FluidSynth(soundfont_path)
        fs.midi_to_audio(out_file, audio_file)


        return render_template('classical.html', midi_file=out_file, instrument_programs=instrument_programs)

    return render_template('classical.html', instrument_programs=instrument_programs, selected_program=selected_program)
    
#Need this to play the MIDI
@app.route('/<path:filename>')
def static_file(filename):
    return send_from_directory('static', filename)



if __name__ == '__main__':
    app.run(debug=True)

# from google.colab import files
# files.download(out_file)

"""# Analysis"""
